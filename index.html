<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AURA STABLE</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/ort.min.js"></script>
    <style>
        body { margin: 0; background: #000; color: #00ffea; font-family: monospace; overflow: hidden; }
        #loader { position: fixed; inset: 0; background: #000; z-index: 100; display: flex; flex-direction: column; align-items: center; justify-content: center; text-align: center; padding: 20px; }
        #camera { width: 100vw; height: 100vh; object-fit: cover; }
        #overlay { position: absolute; inset: 0; z-index: 10; pointer-events: none; }
        #status { position: absolute; top: 0; width: 100%; text-align: center; background: rgba(0,0,0,0.8); padding: 10px; z-index: 20; border-bottom: 1px solid #00ffea; font-size: 12px; }
        #scan-btn { position: absolute; bottom: 40px; left: 50%; transform: translateX(-50%); width: 80px; height: 80px; border-radius: 50%; border: 4px solid #00ffea; background: rgba(0,255,234,0.1); z-index: 20; cursor: pointer; pointer-events: auto; }
    </style>
</head>
<body>

<div id="loader">
    <h2 style="letter-spacing: 5px;">AURA AI</h2>
    <div id="progress">Подготовка ядра...</div>
</div>

<div id="status">ЗАГРУЗКА...</div>
<video id="camera" playsinline muted autoplay></video>
<canvas id="overlay"></canvas>
<div id="scan-btn" onclick="capture()"></div>

<script>
const MODEL_URL = 'https://raw.githubusercontent.com/marataitester-blip/rider-scanner/main/best.onnx';
const NAMES = ["00-TheFool","01-TheMagician","02-TheHighPriestess","03-TheEmpress","04-TheEmperor","05-TheHierophant","06-TheLovers","07-TheChariot","08-Strength","09-TheHermit","10-WheelOfFortune","11-Justice","12-TheHangedMan","13-Death","14-Temperance","15-TheDevil","16-TheTower","17-TheStar","18-TheMoon","19-TheSun","20-Judgement","21-TheWorld","CardBacks","Cups01","Cups02","Cups03","Cups04","Cups05","Cups06","Cups07","Cups08","Cups09","Cups10","Cups11","Cups12","Cups13","Cups14","Pentacles01","Pentacles02","Pentacles03","Pentacles04","Pentacles05","Pentacles06","Pentacles07","Pentacles08","Pentacles09","Pentacles10","Pentacles11","Pentacles12","Pentacles13","Pentacles14","Swords01","Swords02","Swords03","Swords04","Swords05","Swords06","Swords07","Swords08","Swords09","Swords10","Swords11","Swords12","Swords13","Swords14","Wands01","Wands02","Wands03","Wands04","Wands05","Wands06","Wands07","Wands08","Wands09","Wands10","Wands11","Wands12","Wands13","Wands14"];

let session, video, canvas, ctx;

async function run() {
    const progress = document.getElementById('progress');
    try {
        // Настройка ONNX
        ort.env.wasm.wasmPaths = "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.18.0/dist/";
        ort.env.wasm.numThreads = 1; 
        
        progress.innerText = "Связь с GitHub...";
        session = await ort.InferenceSession.create(MODEL_URL, { executionProviders: ['wasm'] });

        progress.innerText = "Активация камеры...";
        video = document.getElementById('camera');
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
        video.srcObject = stream;

        video.onloadedmetadata = () => {
            canvas = document.getElementById('overlay');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx = canvas.getContext('2d');
            document.getElementById('loader').style.display = 'none';
            document.getElementById('status').innerText = "СИСТЕМА АКТИВНА";
            // Включаем предпросмотр
            setInterval(detect, 800); 
        };
    } catch (e) {
        progress.innerHTML = `<span style="color:red">ОШИБКА:<br>${e.message}</span>`;
        console.error(e);
    }
}

async function detect() {
    if (!session || !video.videoWidth) return;

    // Очень легкая обработка для предотвращения зависаний
    const offCanvas = document.createElement('canvas');
    offCanvas.width = offCanvas.height = 800;
    const oCtx = offCanvas.getContext('2d');
    oCtx.drawImage(video, 0, 0, 800, 800);
    
    const imgData = oCtx.getImageData(0, 0, 800, 800).data;
    const input = new Float32Array(3 * 800 * 800);
    for (let i = 0; i < 800 * 800; i++) {
        input[i] = imgData[i * 4] / 255;
        input[i + 800 * 800] = imgData[i * 4 + 1] / 255;
        input[i + 2 * 800 * 800] = imgData[i * 4 + 2] / 255;
    }

    const tensor = new ort.Tensor('float32', input, [1, 3, 800, 800]);
    const output = await session.run({ [session.inputNames[0]]: tensor });
    const boxes = process(output[session.outputNames[0]]);
    
    draw(boxes);
}

function process(out) {
    const d = out.data;
    const res = [];
    for (let i = 0; i < out.dims[2]; i++) {
        let max = 0, cls = -1;
        for (let c = 0; c < 79; c++) {
            let s = d[(c + 4) * out.dims[2] + i];
            if (s > max) { max = s; cls = c; }
        }
        if (max > 0.45) {
            res.push({
                x: d[0 * out.dims[2] + i] * (video.videoWidth / 800),
                y: d[1 * out.dims[2] + i] * (video.videoHeight / 800),
                w: d[2 * out.dims[2] + i] * (video.videoWidth / 800),
                h: d[3 * out.dims[2] + i] * (video.videoHeight / 800),
                name: NAMES[cls]
            });
        }
    }
    return res;
}

function draw(boxes) {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    boxes.forEach(b => {
        ctx.strokeStyle = "#00ffea";
        ctx.lineWidth = 4;
        ctx.strokeRect(b.x - b.w/2, b.y - b.h/2, b.w, b.h);
        ctx.fillStyle = "#00ffea";
        ctx.fillText(b.name, b.x - b.w/2, b.y - b.h/2 - 5);
    });
}

function capture() {
    alert("Расклад зафиксирован!");
}

window.onload = run;
</script>
</body>
</html>
